---
layout: post
title: Week 5
---

Paper reviews continued onto this week.

Paper Review #5:

Title: Classification of Important Segments in Educational Videos using Multimodal Features

Authors: Junaid Ghauri, Sherzod Hakimov, Ralph Ewerth

Institution: Leibniz Information Centre for Science and Technology, Leibniz University (Germany)

Conference: Conference of Information and Knowledge Management.

1. What does the paper talk about?
    - This paper analysis the influence of multimodal features and parameters for educational video summarization.
    - The paper uses multimodal neural network architecture for the prediction of importance scores for video segments.
    - The multimodal architecture consists of the following:
        1. Textual features: based on subtitles provided by each video. Encoded using BERT which creates a dense vector representation to each work in a sentence totalling 768-dimensional vectors.
        2. Audio features: Features that represent the zero-crossing rate, spectral features, energy, entropy. Feature vector is 34 x n, where n is dependent on the window size of the audio clip.
        3. Visual features: Tested various visual models like Xception, ResNet-50, VGG-16. Consider a vector of T sample frames, V = (ft)t=1...T, where ft is the visual frame at point in time t. T depends on the # of selected frames per seconds in a video. In this example, original frame rate is 30fps. Input video is split into 5 second segments from which 3 frames are selected per second. So 10% of total frames per second are used.
    - This paper modeled timestamp importance from a scale of 1-10, using three difference experiments:
        1. Audio and Text features
        2. All three features.
        3. Visual and Audio features.
    - Visual and audio had the best performance. Possible reasons include that the speaker carries more emphasis when they are is denser content to discuss. Additionally, textual features do not provide any insight into the tonality of the lecuterer's speech.

2. How/What can I use from this paper?
    - This paper is very similar to the project that I am working on, just under a different context. Here we are modeling importance while I am more focused on topic modeling. 
    - I anticipate that for my use case the textual features will be of greater importance since I am less worried about the speakers tonality and emphasis.


Paper Review #6:

Title: Summarization of Educational Videos with Transformer Networks

Authors: Ribeiro, Kassio, Chang, Salles.

Institution: Universidade Federal do Maranhao (Brazil)

1. What does the paper talk about?
    - Expands upon the prior work presented in Paper Review #5.
    - Uses 6 step pipeline to generate summarizationsL
        1. Receive trasncription with timestamps.
        2. Transcription summed up into large text and cleaned.
        3. Cleaned text is chunked into sizes of max 3500 characters.
        4. Each chunk goes through summarization using transformer models.
        5. Each heading is correlated with corresponding summary partition and text similarity techniques score from 0-1.
        6. Segments with no heading are assinged 0.

2. How/What can I use from this paper?
    - Text transcription pipeline steps.

Meeting #8: Dr. Lytle
    - Since next week I will be going OOT, this week we discussed the preliminary steps for our dataset labeling.
    - Dr. Lytle and I proposed the following labeling process:
        1. Randomly select 5-10% of relevant video content.
        2. Label and review.
        3. Use this review process to build the schema for tagging the topics.
        4. Think of the theory of fidelity and chunking when labeling.