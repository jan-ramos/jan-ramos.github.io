---
layout: post
title: Week 3
---


This week I focused on model design and paper reviews. 

Paper Review #1:

Title: What Do CS1 Syllabi Reveal About Our Expectations of Introductory Programming Students?

Authors: Brett Becker, Thomas Fitzpatrick

Institution: University College Dublin (Ireland)

1. What does the paper talk about?
    The paper presents efforts towards answering the following key question:
        What exactly do educators expect of introductory programming students?\
    The paper curated 234 introductory progrmamming syllabi and analyzed them for similarities and differences in their key learning components.
    The results highlighted the most frequent computing terms that I can use to help formulate my initial knowledge graph: Programming, Method, Object, Design, Function, Web, Data, Classes, Control, Algorithms, Assingment, Arrays, Test, Security.

2. How/What can I use from this paper?
    Based on the analysis of the paper, the following are the initial knowledge I'll incorporate into my final knowledge graph:
        1. Testing/debugging
        2. Writing Programs
        3. Selection statements
        4. Problem Solving
        5. Arrays, lists, vectors
        6. Basic OOP
        7. Variable Assignment
        8. Arithmetic Operators
        9. Data Types
        10. Functions, methods, procedures
        11. Repetition and loops
        12. Designing algorithms
        13. Classes and Objects
        14. File Handling and I/O.
        15. Documentation
        16. Recursion
        17. Data structures.

Brainstorm Session #1

After going through the initial paper I had a brainstorming session to organize my thoughts. The key idea in this project is how to decompose the knowledge components of a computer science course. We can represent knowledge as a vector K = [x0,x1,...,xn] where each xi represents a core competency idetified to be successful in the course. We can also represent each xi as a vector of vectors. For instance, core competencies can be broken down into further components. As an example, we can denote x0 as Selection Statements and represent x0 as a vector x0 = [x00,x01,...,x0n] where each x0i is a competency of x0. In our example of Selection Statements, x00 can be representative of if/else statements. From here we can label our videos by both their high order competencies x0 and their lower competencies x0i. By increasing our level of granularity, we can assign more labels to our videos. There will have to be a trade-off as too many variables can lead to imprecise results in our model.


Paper Review #2:

Title: Automatic Topic Segmentation for Video Lectures Using Low and High level Audio features.

Authors: Eduardo Soares, Eduardo Barrere.

Institution: Federal University of Juiz de Fora (Brazil)

1. What does the paper talk about?
    - The paper introduces the importance of video lectures as a popular method for disseminating educational content. It introduces the notion of the difficulty of finding relevant content associated with educational content due to the large amounts of available content. As such it proposes a method of automatic topic segmentation based on early fusion of low and high level audio features. 
    - As stated, their method of topic segmentation incorporates low-level acoustic features (pitch, loudness, syllable sound length, pause rate, etc.) to assing emphasis factor, combined with high level features (cue words and phrases, word representations, term freequencies, sentence location, etc.). The study performed experiments using high and low level features in isolation and combined and saw increased performance when using both.
    - To expand further on the methodology, the author presents two levels of lingustic approach comprising of content-based and discourse-based features. Content-based features are composed of linguestic structures like noun phrases, verb classes, word stems, etc. Discourse-based is composed of pronounds and cue phrases. Content-based structures are more related to the lexical and syntatctical meaning of the body of contence while discourse-based structure have more to do with "neighborhoods" of hypothetical topic boundaries. From these two linguistic approaches a vector space is then built with weights for each feature in a window of fixed sized transcript sentences. They also incorporate a knowledge graph, since background/outside knowledge cannot be obtained from just the video.


2. How/What can I use from the paper?
    - The notion that video can differ from other forms of content because emphasis is placed on the lecturers speech.
    - The incoroporation of both low-level and high-level audio features into my multimodal model.
    - Additionally the following steps I can replicate for my own neuro-topic model:
        1. Step 1
            * Audio Extraction.
            * Silence Detection.

        2. Step 2
            * Frequency and feature vector extraction.
            * Affinity matrix calculations.
        
        3. Step 3
            * Audio Transcription.
            * Vector space is built and Affinity matrix is calculated.

        4. Step 4
            * Semantic annotations
            * Knowledge based searches

        5. Step 5
            * Vector space is built and affinity matrix is calculated.
        
        6. Step 6
            * Linear combinations.
            * Spectral clustering.

    - To expand further...Step 1 features Audio extraction and silence detection. For Video V, we process V and obtain the audio track. The silence detection is used as lecturers typicall takes longer pauses when tryring to emphasize a point. In Step 2 we try to find the fundamental frequencies and power spectral density. When speakers want to emphasize something they speak lourder and change the pitch of their voice. These variations provide good context for change in subject. Step 3 transcribes the audio, for our use-case we will use openAI whisper model to transcribe and BERT tokenizer to build the vector space. Step 4 incorporates semantic annotations and knowledge based searches that we will use for the topic labeling.

Meeting #5: Edx Data Governance Team
    - Since I will be using GaTech's 1301 Introduction to Programming course for my work, I met with GaTech's data governance team to get access to the MongoDB and PostGres databases. 

Meeting #6: Dr. Lytle
    - In this meeting we discussed going through similar works submitted to our conferences of interest: EAAI, (J)AIED, (J)EDM. The goal being to find related papers with code that we can use as a starting point for our work.