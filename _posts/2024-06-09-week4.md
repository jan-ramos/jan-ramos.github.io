---
layout: post
title: Week 4
---

This week I focused on model design and paper reviews. Additionally, I worked on the video processing pipeling.

Paper Review #3:

Title: Incorporating Domain Knowledge to Improve Topic Segmentation of Long MOOC Lecture Videos.

Authors: Ananda Das, Parth Das.

Institution: Indian Institute of Kharagpur (India)

1. What does the paper talk about?
    - Incorporates domain knowledge by leveraging both structural analysis of transcripts and semantic analysis using domain knowledge from knowledge graphs.
    - Knowledge graphs: Structural representations of information that capture entities, their properties and the relationships between them in a graphical format.
    - Three main contributions:
        1. Use language model that understands implicit meaning of the text data and capture semantics in local context for small topics.
        2. Capture the semantics in global context by use of domain knowledge graph that detects segement boundaries for large topics.
        3. Use findings to analyze ways the instructor binds different topics.

    - Methodology:
        1. Structural Analysis: 
            - Transcript processing: divided into strings of fixed length.
            - Sentence encoding: pre-trained sentence encoder to create sentence vectors.
            - Sentence classification (binary): given a sentence  with K sized left and right contexts, decide whether sentence is the beginning of a segment or not.
        2. Semenatic Analysis:
            - Domain knowledge integration: leverages domain knowledge from knowledge grapsh to segment.
            - Contextual fusion: results from structural and semantic analysis are fused to obtain accurate topic boundaries.
        3. Annotation Fusion:
            - Segment annotation: After identifying topic boundaries, topic name is derived from course syllabus.
            - Structural and semantic boundary info fused to refine topic boundaries.

2. How/What can I use from this paper?
    - The methodology proposed in this paper will provide ample background for my work.


Paper Review #4:

Title: Topic Based Segmentation of Classroom Videos

Authors: Tuna, Joshi, Varghese, Deshpande, Subhlock, Verma.

Institution: Univeristy of Houston (USA)

1. What does the paper talk about?
    - Proposes a system called ICS (Indexed, Captioned, Searchable) that automatically partitions a video lecture into segments based on image and text analysis.
    - Incorporates Object Character Recognition (OCR) and Automatic Speech Detection (ASD) in topic based segmentation.
    - Methodology: there are four types of text used in modeling
        1. screen text: OCR ie. lecture slides.
        2. speech text: ASR ie. YouTube.
        3. hybrid text: Union of screen and speech text.
        4. corrected speech text: ASR tools generate errors so these are the manual corrections.
    - Text-based indexing, in order to process video data, segmentation technique should detect scene changes.
    - Text similarity metric used is cosine similarity.
    - Results show that screen text led to more accurate segmenation in comparison with speech text from ASR. This could be because the lecture content relied heavily on lecture slides that contained course content.

2. How/What can I use from this paper?
    - This paper highlighted the importance of differentiating between lecture medium. For example, some lecture content can rely on lecture sides, live coding, blackboard writing etc. As such, we should weight each one of these mediums differently as they could have different accuracy results when topic modeling.
    - Considering that the YouTube ASR tool performed poorly, I will transcribe my audio using more state of the art tools like OpenAI's Whisper model.
    - To measure the accuracy of my ASR transcriptions I will also use cosine similarity.

Meeting #7
    - Met with Dr. Lytle to discuss pending items regarding data access. Confirmed I have data access and proposed a preliminary comparison of Edx generated close captions with YouTube generated transcripts and openAI Whisper video transcripts.
    - Plan is to continue to go through relevant papers.

This week I also created the pipeline for downloading the Edx video content. Additionally, I conducted an experiment comparing the three different levels of audio transcriptions:
    1. Edx transcriptions
    2. YouTube transcriptions
    3. OpenAI Whisper transcriptions

Of the three, OpenAI Whisper and the Edx transcriptions had the highest similarity percentage. I measured similarity using cosine similarity as proposed in Paper Review #4. YouTube generated transcriptions were the poorest of the three and will not be used for our pipeline.