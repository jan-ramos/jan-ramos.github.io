---
layout: post
title: Week 11
---

This week I decided to transition the project from a classification approach to a vector database structured system. This shift was motivated by recent papers I had read on efficient content retrieval. VDBMS are also easy to scale since the compute required for generating the embeddings is significantly lower than with the prior approach.


Paper Review #8:

Title: MUVERA: Multi-Vector Retrieval via Fixed Dimensional Encodings

Authors: Laxman Dhulipala, Majid Hadian, Rajesh Jayaram, Jason Lee, Vahab Mirrokni

Institution: Google Research, Google DeepMind, UMD

Paper URL: https://arxiv.org/abs/2405.19504

1. What does the paper talk about?
    - The paper presents MUVERA, a novel retrieval mechanism that reduces multi-vector similarity search to single-vector similarity search
    - Key innovation: Fixed Dimensional Encodings (FDEs) - vectors whose inner product approximates multi-vector similarity
    - Main components:
        1. Asymmetric encoding: Generates different fixed-dimensional encodings for queries and documents
        2. Theoretical guarantees: Proves FDEs give high-quality Îµ-approximations
        3. Practical improvements: Introduces optimizations like product quantization for 32x compression
    - Methodology:
        1. Takes multi-vector inputs (sets of embeddings for queries/documents)
        2. Maps them to fixed-dimensional vectors using careful random projections
        3. Enables use of standard MIPS solvers for retrieval
        4. Incorporates ball carving and quantization for efficiency 


2. How/What can I use from this paper?
    The paper is particularly relevant as it addresses key challenges in scaling multi-vector retrieval systems while maintaining quality. Not sure how relevant this paper will be for the current scope of this project.


Paper Review #9:

Title: Supporting Teaching-to-the-Curriculum by Linking Diagnostic Tests to Curriculum Goals: Using Textbook Content as Context for Retrieval-Augmented Generation with Large Language Models

Authors: Xiu Li, Aron Henriksson, Martin Duneld, Jalal Nouri, Yongchao Wu

Institution: Stockholm University, Sweden

Paper URL: https://link.springer.com/chapter/10.1007/978-3-031-64302-6_9

Conference: AIED

1. What does the paper talk about?
   - Introduces a novel task of automatically linking diagnostic test questions to curriculum goals to support teaching-to-the-curriculum
   - Key components:
       1. Created manually labeled dataset linking diagnostic tests to curriculum goals for Biology G7-9 in Sweden
       2. Explored two task formulations:
           * Information Retrieval (IR) using semantic textual similarity (STS)
           * Multi-class classification using ChatGPT
       3. Investigated using textbook content as additional context through Retrieval-Augmented Generation (RAG)
   - Methodology:
       1. STS approach using ADA-002 embedding model for retrieving relevant content
       2. Zero-shot ChatGPT prompting for classification
       3. Combined approach using RAG where STS retrieves textbook content as context for ChatGPT
   - Results show:
       - RAG model achieved best classification accuracy (73.5%)
       - Outperformed both standalone STS (67.5%) and LLM without context (71.5%)
       - Using paragraph-level context was more effective than broader subsection-level context

2. How/What can I use from this paper?
   - The RAG-based approach is something I want to incorporate into my output. It can consolidate the highest ranked similarity metrics.

